{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694772ce",
   "metadata": {},
   "source": [
    "### Building RAG MultiModal Search: Weaviate + OLLAMA + CLIP Multimodal Embedding Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "829f7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType, Multi2VecField\n",
    "from weaviate.util import generate_uuid5\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import weaviate\n",
    "import pandas as pd\n",
    "import base64\n",
    "import weaviate.classes.query as wq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d323012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the local Weaviate instance\n",
    "client = weaviate.connect_to_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50f03061",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert client.is_live() # Checks if the Weaviate server is live."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21f97d",
   "metadata": {},
   "source": [
    "### ◻️ Create `WomenShoesMM` Collection adding Generative Integration Capability\n",
    "A generative integration in Weaviate refers to the ability to connect Weaviate with external generative AI models (such as LLMs) to enable retrieval augmented generation (RAG) functions. Weaviate offers different providers, such as OpenAI, Cohere, Anthropic, Mistral, NVIDIA, Anyscale, FriendliAI, xAI, OctoAI, AWS, and more, to configure a collection in Weaviate to use a generative module. Each collection can be set up with a generative module independently of its vectorizer module. \n",
    "\n",
    "⚠️ Important: \n",
    "* `.Vectorizer` (Deprecated):\n",
    "In older versions of the Weaviate Python client (before v4.16.0), you would use Configure.Vectorizer to specify the vectorizer module for your collection. \n",
    "```bash\n",
    "vectorizer_config=Configure.Vectorizer.text2vec_openai()\n",
    "```\n",
    "\n",
    "* `.Vectors` (Current):\n",
    "Starting with Weaviate Python client v4.16.0, the API was updated to use Configure.Vectors instead. This new approach is more flexible and supports both single and multiple named vector.\n",
    "```bash\n",
    "vector_config=Configure.Vectors.multi2vec_clip(\n",
    "    image_fields=[Multi2VecField(name=\"image\")],\n",
    "    text_fields=[Multi2VecField(name=\"description\")]\n",
    ")\n",
    "```\n",
    "\n",
    "⚠️ Important:  To apply changes to your docker-compose.yml (such as adding generative-ollama to ENABLE_MODULES), you need to restart your Weaviate container so it picks up the new environment variable.The standard way to do this is:\n",
    "\n",
    "1. Stop the running containers\n",
    "```bash\n",
    "docker compose down\n",
    "```\n",
    "2. Start the containers again\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "This will recreate the Weaviate container with the updated configuration. You do not need to rebuild the image unless you have changed the Dockerfile itself; updating environment variables in docker-compose.yml and restarting is sufficient Modules configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eabea7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a collection named \"Animals\" exists on the Weaviate server. If the collection exists, delete it.\n",
    "if(client.collections.exists(\"WomenShoesMM\")):\n",
    "    client.collections.delete(\"WomenShoesMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8524419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x1edbac63310>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a WomenShoesMM collection with multi-modal vectorization and generative AI capabilities\n",
    "client.collections.create(\n",
    "    name=\"WomenShoesMM\",\n",
    "    properties=[\n",
    "        Property(name=\"name\", data_type=DataType.TEXT),\n",
    "        Property(name=\"description\", data_type=DataType.TEXT),\n",
    "        Property(name=\"currency\", data_type=DataType.TEXT),\n",
    "        Property(name=\"price\", data_type=DataType.NUMBER),\n",
    "        Property(name=\"image_path\", data_type=DataType.TEXT),\n",
    "        Property(name=\"image\", data_type=DataType.BLOB),\n",
    "    ],\n",
    "    vector_config=Configure.Vectors.multi2vec_clip(\n",
    "        image_fields=[Multi2VecField(name=\"image\")],\n",
    "        text_fields=[Multi2VecField(name=\"description\")]\n",
    "    ),\n",
    "    generative_config=Configure.Generative.ollama(\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",  # Adjust as needed for your setup\n",
    "        model=\"llava7b\"  # Replace with your preferred Ollama model\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231fa9c",
   "metadata": {},
   "source": [
    "### ◻️ Add women shoes info to WomenShoesMM Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b93cf2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>terms</th>\n",
       "      <th>image_downloads</th>\n",
       "      <th>extracted_footwear_type</th>\n",
       "      <th>iso_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PEARL HEELED SLINGBACKS</td>\n",
       "      <td>Slingback heels with front pearl detail. Point...</td>\n",
       "      <td>79.9</td>\n",
       "      <td>USD</td>\n",
       "      <td>shoes</td>\n",
       "      <td>['82aaf07d-4981-46d9-ab54-56d82c40cfa5', 'ea8b...</td>\n",
       "      <td>SLINGBACKS</td>\n",
       "      <td>ea8b9976-7cda-4e4c-9926-b357b1aa65c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LEATHER BALLET FLATS</td>\n",
       "      <td>Mary Jane style leather ballet flats. Buckled ...</td>\n",
       "      <td>59.9</td>\n",
       "      <td>USD</td>\n",
       "      <td>shoes</td>\n",
       "      <td>['3c5a4b1d-407b-4683-8489-795e1177aa4a', '769a...</td>\n",
       "      <td>BALLET FLATS</td>\n",
       "      <td>769a6f42-94a6-451b-9014-5fcf1100d212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                        description  \\\n",
       "0  PEARL HEELED SLINGBACKS  Slingback heels with front pearl detail. Point...   \n",
       "1     LEATHER BALLET FLATS  Mary Jane style leather ballet flats. Buckled ...   \n",
       "\n",
       "   price currency  terms                                    image_downloads  \\\n",
       "0   79.9      USD  shoes  ['82aaf07d-4981-46d9-ab54-56d82c40cfa5', 'ea8b...   \n",
       "1   59.9      USD  shoes  ['3c5a4b1d-407b-4683-8489-795e1177aa4a', '769a...   \n",
       "\n",
       "  extracted_footwear_type                             iso_image  \n",
       "0              SLINGBACKS  ea8b9976-7cda-4e4c-9926-b357b1aa65c7  \n",
       "1            BALLET FLATS  769a6f42-94a6-451b-9014-5fcf1100d212  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from a CSV file\n",
    "women_df = pd.read_csv(\"data/women_shoes.csv\", sep=\",\")\n",
    "print(women_df.shape)\n",
    "women_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d548113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the collection\n",
    "women_shoes_mm = client.collections.use(\"WomenShoesMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f27ea0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "277it [00:30,  9.21it/s] \n"
     ]
    }
   ],
   "source": [
    "# Enter context manager\n",
    "with women_shoes_mm.batch.fixed_size(50) as batch: \n",
    "    # Loop through the data\n",
    "    for i, row in tqdm(women_df.iterrows()):\n",
    "        # Convert image to base64\n",
    "        img_dir = 'data/iso_women_shoes/'\n",
    "        img_path = (img_dir + f\"{row['iso_image']}.jpg\")\n",
    "        with open(img_path, \"rb\") as file:\n",
    "            image_b64 = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "            #image_b64 = convert_toBase64(img_path) \n",
    "\n",
    "        # Build the object payload\n",
    "        shoe_obj = {\n",
    "            \"name\": row[\"name\"],\n",
    "            \"description\": row[\"description\"],\n",
    "            \"price\": row[\"price\"],\n",
    "            \"currency\": row[\"currency\"],\n",
    "            \"image_path\": img_path,\n",
    "            \"image\": image_b64\n",
    "        }\n",
    "\n",
    "        # Add data to the batch\n",
    "        batch.add_object(\n",
    "            properties=shoe_obj,\n",
    "            uuid=generate_uuid5(row[\"iso_image\"])\n",
    "        )# Batcher automatically sends batches\n",
    "\n",
    "        \n",
    "# Check for failed objects\n",
    "if len(women_shoes_mm.batch.failed_objects) > 0:\n",
    "    print(f\"Failed to import {len(women_shoes_mm.batch.failed_objects)} objects\")\n",
    "    for failed in women_shoes_mm.batch.failed_objects:\n",
    "        print(f\"e.g. Failed to import object with error: {failed.message}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865e044",
   "metadata": {},
   "source": [
    "### ◻️ Retrieval Augmented Generation (RAG) \n",
    "Retrieval Augmented Generation (RAG) combines information retrieval with generative AI models.\n",
    "\n",
    "In Weaviate, a RAG query consists of two parts: a search query, and a prompt for the model. Weaviate first performs the search, then passes both the search results and your prompt to a generative AI model before returning the generated response.\n",
    "\n",
    "After configuring the generative AI integration, perform RAG operations, either with the `single prompt` or `grouped task` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245a38d",
   "metadata": {},
   "source": [
    "`query`\n",
    "- Purpose: Specifies the search criteria for retrieving objects from your Weaviate collection.\n",
    "- How it works: The query is vectorized (by the model provider integration) and used to find the most relevant objects in the collection.\n",
    "\n",
    "\n",
    "`single_prompt`\n",
    "- Purpose: Generates a separate output for each object in the search results.\n",
    "- How it works: You provide a prompt with placeholders (e.g., {title}) that are filled with properties from each object.\n",
    "The generative model produces an output for each object individually.\n",
    "- Result: Each object in the response includes its own generated output.\n",
    "\n",
    "![single_prompt.png](https://docs.weaviate.io/assets/images/integration_ollama_rag_single-e404950fa7a2120110acf80c697ef6ff.png)\n",
    "\n",
    "\n",
    "`grouped_task`\n",
    "- Purpose: Generates a single output for the entire set of search results.\n",
    "- How it works: You provide a prompt that considers the whole group of results.The generative model produces one output based on all the objects together.\n",
    "- Result: The response contains one generated output for the group, plus the list of objects.\n",
    "\n",
    "![grouped_task.png.png](https://docs.weaviate.io/assets/images/integration_ollama_rag_grouped-190b744e3fcbe9dfb0a4ac25ae3e0792.png)\n",
    "\n",
    "🔗 Resource: [Ollama Generative AI with Weaviate](https://docs.weaviate.io/weaviate/model-providers/ollama/generative#retrieval-augmented-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bfffb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n"
     ]
    }
   ],
   "source": [
    "# Verify the number of objects in the collection\n",
    "response_0 = women_shoes_mm.aggregate.over_all(total_count=True)\n",
    "print(response_0.total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0446fe6",
   "metadata": {},
   "source": [
    "## Multimodal Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e543c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_response_0 = women_shoes_mm.generate.near_text(\n",
    "    query='Show sandals with a heel height of 9cm',\n",
    "    limit=1,\n",
    "    single_prompt=\"Describe each shoe using: {description}, {price}, {currency}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the response\n",
    "for o in mm_response_0.objects:\n",
    "    display(Image.open(o.properties[\"image_path\"]).resize((150, 100)))\n",
    "    print(o.properties[\"description\"], o.properties[\"price\"], o.properties[\"currency\"])  # Print the title\n",
    "    print(o.generated)  # Print the generated text "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
